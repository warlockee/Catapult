# Dockerfile optimized for NVIDIA A100 GPU (Compute Capability 8.0)
# This version removes T4-specific workarounds and enables A100 features:
# - V1 engine support (faster, more features)
# - Native bfloat16 support
# - FlashAttention-2 support
# - Uses 3B model for better quality

FROM mcr.microsoft.com/azureml/curated/foundation-model-inference:latest

ARG CUDA_VERSION=12.4.1
ARG PYTHON_VERSION=3.12

WORKDIR /vllm-workspace
COPY . .

ENV DEBIAN_FRONTEND=noninteractive
ARG TARGETPLATFORM

ARG max_jobs=32
ENV MAX_JOBS=${max_jobs}
# number of threads used by nvcc
ARG nvcc_threads=64
ENV NVCC_THREADS=$nvcc_threads

# Precompiled wheel support
# Place precompiled wheel at .build-wheels/vllm-precompiled.whl to use it

RUN PYTHON_VERSION_STR=$(echo ${PYTHON_VERSION} | sed 's/\.//g') && \
    echo "export PYTHON_VERSION_STR=${PYTHON_VERSION_STR}" >> /etc/environment

# Install Python 3.12 first to match the precompiled wheels
RUN apt-get update && apt-get install -y curl python3.12 python3.12-venv python3.12-dev && \
    update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.12 1 && \
    curl -sS https://bootstrap.pypa.io/get-pip.py | python3.12

# uninstall vllm to avoid version conflict
RUN /azureml-envs/default/bin/python -m pip uninstall --yes vllm

# cuda arch list used by torch
# A100 specific: Includes 8.0 and 8.9 for Ampere architecture
ARG torch_cuda_arch_list='7.0 7.5 8.0 8.6 8.9 9.0+PTX'
ENV TORCH_CUDA_ARCH_LIST=${torch_cuda_arch_list}
# Override the arch list for flash-attn to reduce the binary size
# A100 optimization: Targets 8.0 (A100) and 9.0 (H100) architectures
ARG vllm_fa_cmake_gpu_arches='80-real;90-real'
ENV VLLM_FA_CMAKE_GPU_ARCHES=${vllm_fa_cmake_gpu_arches}

ENV CCACHE_DIR=/root/.cache/ccache
RUN python3.12 -m pip install "setuptools_scm==9.2.1"

# Install PyTorch 2.6.0 with CUDA 12.4 support for Python 3.12
RUN python3.12 -m pip uninstall --yes torch torchvision torchaudio
RUN python3.12 -m pip install torch==2.6.0
RUN python3.12 -m pip install torchvision==0.21.0
RUN python3.12 -m pip install torchaudio==2.6.0

# A100 OPTIMIZATION: Install latest xformers (no version pinning needed for A100)
# Note: T4 required xformers==0.0.29 specifically, A100 is more flexible
RUN python3.12 -m pip uninstall --yes xformers
RUN python3.12 -m pip install xformers --no-deps

# FlashInfer for optimized attention on A100
RUN python3.12 -m pip install https://github.com/flashinfer-ai/flashinfer/releases/download/v0.2.1.post2/flashinfer_python-0.2.1.post2+cu124torch2.6-cp38-abi3-linux_x86_64.whl

# Install vLLM from precompiled wheel (required)
# Copy wheel from host system to build context
COPY .build-wheels/vllm-0.10.2-cp312-cp312-linux_x86_64.whl /tmp/
RUN python3.12 -m pip install /tmp/vllm-0.10.2-cp312-cp312-linux_x86_64.whl && \
    rm /tmp/vllm-0.10.2-cp312-cp312-linux_x86_64.whl && \
    rm -rf /vllm-workspace/vllm /vllm-workspace/setup.py /vllm-workspace/setup.cfg /vllm-workspace/CMakeLists.txt /vllm-workspace/cmake

# Workaround for https://github.com/openai/triton/issues/2507 and
# https://github.com/pytorch/pytorch/issues/107960
RUN ldconfig /usr/local/cuda-$(echo $CUDA_VERSION | cut -d. -f1,2)/compat/

# Install extra dependencies
COPY requirements/extra.txt requirements/extra.txt
RUN python3.12 -m pip install -r requirements/extra.txt

# Install xcodec audio tokenizer module
COPY third_party/xcodec /vllm-workspace/third_party/xcodec
# Fix scipy version requirement (1.10.1 doesn't exist, use 1.11.4 instead)
RUN sed -i 's/scipy==1.10.1/scipy==1.11.4/g' /vllm-workspace/third_party/xcodec/requirements.txt && \
    sed -i 's/scipy==1.10.1/scipy==1.11.4/g' /vllm-workspace/third_party/xcodec/setup.py
# Fix descript-audio-codec import (package installs as 'dac' not 'descriptaudiocodec')
RUN sed -i 's/import descriptaudiocodec\.dac\.model\.dac/import dac.model.dac/g' /vllm-workspace/third_party/xcodec/xcodec/models/soundstream_semantic.py
# Fix missing __init__.py in semantic directory (needed for package discovery)
RUN touch /vllm-workspace/third_party/xcodec/xcodec/models/semantic/__init__.py
RUN python3.12 -m pip install /vllm-workspace/third_party/xcodec

# Install vllm development version (custom build with audio support)
COPY .build-wheels/vllm-0.1.dev9525+gcc3a60157.d20250930-cp312-cp312-linux_x86_64.whl /tmp/
RUN python3.12 -m pip install /tmp/vllm-0.1.dev9525+gcc3a60157.d20250930-cp312-cp312-linux_x86_64.whl --no-deps && \
    rm /tmp/vllm-0.1.dev9525+gcc3a60157.d20250930-cp312-cp312-linux_x86_64.whl

# A100 OPTIMIZATION: Use multimodal checkpoint model
# Copy model files into the image
COPY models/audio-multimodal-checkpoint-1200 /vllm-workspace/models/audio-multimodal-checkpoint-1200
COPY models/xcodec_tps25_0516_exp_1 /vllm-workspace/models/xcodec_tps25_0516_exp_1

RUN python3.12 -m pip install "boto3==1.35.57"
RUN python3.12 -m pip install "botocore==1.40.45"

# A100 OPTIMIZED ENTRYPOINT:
# - Uses 3B model instead of 1B (better quality, A100 can handle it)
# - NO --dtype half flag (A100 supports bfloat16 natively, will auto-select)
# - V1 engine will be enabled via environment variable in deployment.yaml
# - Uses Python 3.12 to match precompiled vLLM wheel
ENTRYPOINT ["python3.12", \
    "-m", "vllm.entrypoints.openai.api_server", \
    "--port", "26000", \
    "--model", "/vllm-workspace/models/audio-multimodal-checkpoint-1200", \
    "--served-model-name", "audio-multimodal-checkpoint-1200", \
    "--audio-tokenizer-type", "xcodec_0516_exp_1", \
    "--audio-tokenizer-path", "/vllm-workspace/models/xcodec_tps25_0516_exp_1", \
    "--max-model-len", "8192", \
    "--limit-mm-per-prompt", "{\"audio\": 50}", \
    "--gpu-memory-utilization", "0.8", \
    "--disable-mm-preprocessor-cache"]
